{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737ec0f-66e9-41aa-83b5-d3cbf37fb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop predict using latest generate softmax\n",
    "import torch\n",
    "from batchgenerators.utilities.file_and_folder_operations import join\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import pickle\n",
    "\n",
    "def list_labels(directory):\n",
    "    file_paths = []  # List to store the file paths\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def list_outputs(directory):\n",
    "    file_paths = []  # List to store the file paths\n",
    "    entries = os.listdir(directory)\n",
    "    folds = [entry for entry in entries if os.path.isdir(os.path.join(directory, entry))]\n",
    "    for f in folds:\n",
    "        subfolder = directory + f + '/validation'\n",
    "        for root, dirs, files in os.walk(subfolder):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                if file.endswith('.nii.gz'):\n",
    "                    file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "# instantiate the nnUNetPredictor\n",
    "if __name__ == \"__main__\":\n",
    "    nnUNet_results = 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV'\n",
    "    nnUNet_raw = 'Z:/Imaging/Multimodal/MRF/Recon_MRF_3T/Patients/MRF_to_nnunet/nnUNet_raw'\n",
    "    predictor = nnUNetPredictor(tile_step_size=0.5,\n",
    "            use_gaussian=True,\n",
    "            use_mirroring=True,\n",
    "            perform_everything_on_device=True,\n",
    "            device=torch.device('cuda', 0),\n",
    "            verbose=False,\n",
    "            verbose_preprocessing=False,\n",
    "            allow_tqdm=True)\n",
    "\n",
    "    directory = join(nnUNet_results, 'Dataset022_T1wT1T2pt/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres')\n",
    "    entries = os.listdir(directory)\n",
    "    folds = [entry for entry in entries if os.path.isdir(os.path.join(directory, entry))]\n",
    "    last_2 = [item[-2:] for item in folds]\n",
    "\n",
    "    for ind, f in enumerate(last_2):\n",
    "        if f[0] == '_':\n",
    "            fold = int(f[-1])\n",
    "        else:\n",
    "            fold = int(f) \n",
    "        indir = join(nnUNet_raw, 'Dataset019_vbm/imagesTr')\n",
    "        for root, dirs, files in os.walk(indir):\n",
    "            flist = files\n",
    "        \n",
    "        try:\n",
    "            predictor.initialize_from_trained_model_folder(\n",
    "                    join(nnUNet_results, 'Dataset016_MRFz/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres'),\n",
    "                    use_folds=(fold,),\n",
    "                    checkpoint_name='checkpoint_best.pth')\n",
    "        except:\n",
    "           predictor.initialize_from_trained_model_folder(\n",
    "                    join(nnUNet_results, 'Dataset016_MRFz/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres'),\n",
    "                    use_folds=(fold,),\n",
    "                    checkpoint_name='checkpoint_final.pth')\n",
    "        outdir = join(nnUNet_results, 'Dataset016_MRFz/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres_softmax/')\n",
    "        \n",
    "        predictor.predict_from_files([[join(indir, flist[fold*8]), join(indir, flist[fold*8+1]),\n",
    "                                       join(indir, flist[fold*8+2]), join(indir, flist[fold*8+3]),\n",
    "                                       join(indir, flist[fold*8+4]), join(indir, flist[fold*8+5]),\n",
    "                                       join(indir, flist[fold*8+6]), join(indir, flist[fold*8+7])]],\n",
    "                                     [join(outdir, flist[fold*8][:-12] + '.nii.gz')],\n",
    "                                     save_probabilities=True, overwrite=False,\n",
    "                                     num_processes_preprocessing=2, num_processes_segmentation_export=2,\n",
    "                                     folder_with_segs_from_prev_stage=None, num_parts=1, part_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96fe827-c1be-4e72-8ac2-f5b4632c7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop find lacked predictions and predict using best\n",
    "import torch\n",
    "from batchgenerators.utilities.file_and_folder_operations import join\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import pickle\n",
    "\n",
    "def list_labels(directory):\n",
    "    file_paths = []  # List to store the file paths\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def list_outputs(directory):\n",
    "    file_paths = []  # List to store the file paths\n",
    "    entries = os.listdir(directory)\n",
    "    folds = [entry for entry in entries if os.path.isdir(os.path.join(directory, entry))]\n",
    "    for f in folds:\n",
    "        subfolder = directory + f + '/validation'\n",
    "        for root, dirs, files in os.walk(subfolder):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                if file.endswith('.nii.gz'):\n",
    "                    file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "# instantiate the nnUNetPredictor\n",
    "if __name__ == \"__main__\":\n",
    "    nnUNet_results = 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV'\n",
    "    nnUNet_raw = 'Z:/Imaging/Multimodal/MRF/Recon_MRF_3T/Patients/MRF_to_nnunet/nnUNet_raw'\n",
    "    predictor = nnUNetPredictor(tile_step_size=0.5,\n",
    "            use_gaussian=True,\n",
    "            use_mirroring=True,\n",
    "            perform_everything_on_device=True,\n",
    "            device=torch.device('cuda', 0),\n",
    "            verbose=False,\n",
    "            verbose_preprocessing=False,\n",
    "            allow_tqdm=True)\n",
    "\n",
    "    directory = join(nnUNet_results, 'Dataset023_nosmooth/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres')\n",
    "    entries = os.listdir(directory)\n",
    "    folds = [entry for entry in entries if os.path.isdir(os.path.join(directory, entry))]\n",
    "    last_2 = [item[-2:] for item in folds]\n",
    "\n",
    "    for ind, f in enumerate(last_2):\n",
    "        if f[0] == '_':\n",
    "            fold = int(f[-1])\n",
    "        else:\n",
    "            fold = int(f) \n",
    "        indir = join(nnUNet_raw, 'Dataset023_nosmooth/imagesTr')\n",
    "        for root, dirs, files in os.walk(indir):\n",
    "            flist = files\n",
    "      \n",
    "        predictor.initialize_from_trained_model_folder(\n",
    "                join(nnUNet_results, 'Dataset023_nosmooth/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres'),\n",
    "                use_folds=(fold,),\n",
    "                checkpoint_name='checkpoint_best.pth')\n",
    "        outdir = join(nnUNet_results, 'Dataset023_nosmooth/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres/' + folds[ind] + '/validation')\n",
    "        # print(outdir)\n",
    "        \n",
    "\n",
    "        if os.path.exists(outdir) and os.path.isdir(outdir):\n",
    "            continue\n",
    "        else:\n",
    "            # predictor.predict_from_files([[join(indir, flist[fold*6]), join(indir, flist[fold*6+1]),\n",
    "            #                            join(indir, flist[fold*6+2]), join(indir, flist[fold*6+3]),\n",
    "            #                            join(indir, flist[fold*6+4]), join(indir, flist[fold*6+5])]],\n",
    "            #                          [join(outdir, flist[fold*6][:-12] + '.nii.gz')],\n",
    "            #                          save_probabilities=False, overwrite=False,\n",
    "            #                          num_processes_preprocessing=2, num_processes_segmentation_export=2,\n",
    "            #                          folder_with_segs_from_prev_stage=None, num_parts=1, part_id=0)\n",
    "            predictor.predict_from_files([[join(indir, flist[fold*8]), join(indir, flist[fold*8+1]),\n",
    "                                       join(indir, flist[fold*8+2]), join(indir, flist[fold*8+3]),\n",
    "                                       join(indir, flist[fold*8+4]), join(indir, flist[fold*8+5]),\n",
    "                                       join(indir, flist[fold*8+6]), join(indir, flist[fold*8+7])]],\n",
    "                                     [join(outdir, flist[fold*8][:-12] + '.nii.gz')],\n",
    "                                     save_probabilities=False, overwrite=False,\n",
    "                                     num_processes_preprocessing=2, num_processes_segmentation_export=2,\n",
    "                                     folder_with_segs_from_prev_stage=None, num_parts=1, part_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e66759c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import pickle\n",
    "\n",
    "\n",
    "def process_nifti_file(nifti_file_path, binary_label_path):\n",
    "    img = nib.load(nifti_file_path)\n",
    "    data = img.get_fdata()\n",
    "    olwithin = 0\n",
    "    label_img = nib.load(binary_label_path)\n",
    "    label_data = label_img.get_fdata()\n",
    "    # Count non-overlapping clusters\n",
    "    overlap = (data.astype(int) & label_data.astype(int)).astype(bool)\n",
    "    overlap_per = np.sum((data.astype(int) & (label_data > 0).astype(int)))/(np.sum(label_data.astype(int)))\n",
    "    dsc = 2*np.sum((data.astype(int) & (label_data > 0).astype(int)))/(np.sum((label_data > 0).astype(int))+np.sum(data.astype(int)))\n",
    "    has_overlap = np.any(overlap)\n",
    "\n",
    "    structure = np.ones((3, 3, 3), dtype=int)\n",
    "    labeled_array, num_features = ndimage.label(data > 0, structure=structure)\n",
    "    \n",
    "    non_overlapping_clusters = 0\n",
    "    for cluster_id in range(1, num_features + 1):\n",
    "        cluster_mask = labeled_array == cluster_id\n",
    "        overlap = np.any(\n",
    "            cluster_mask & (label_data > 0))  # Assuming nonzero values in label_data indicate labeled regions\n",
    "        if not overlap:\n",
    "            non_overlapping_clusters += 1\n",
    "        else:\n",
    "            olwithin = np.sum(cluster_mask & (label_data > 0).astype(int))/(np.sum(cluster_mask))\n",
    "        \n",
    "    return has_overlap, non_overlapping_clusters, data, overlap_per, olwithin, dsc\n",
    "\n",
    "\n",
    "def list_labels(directory):\n",
    "    file_paths = []  # List to store the file paths\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def list_outputs(directory):\n",
    "    file_paths = []  # List to store the file paths\n",
    "    entries = os.listdir(directory)\n",
    "    folds = [entry for entry in entries if os.path.isdir(os.path.join(directory, entry))]\n",
    "    for f in folds:\n",
    "        subfolder = directory + f + '/validation'\n",
    "        for root, dirs, files in os.walk(subfolder):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                if file.endswith('.nii.gz') and not file.endswith('_softmax.nii.gz'):\n",
    "                    file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nifti_file_paths = list_outputs(\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV\\Dataset009_MRF_clin/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV\\Dataset003_MRF_T1w/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV\\Dataset008_MRF_agegender/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV\\Dataset007_MRF_T1T2z/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/Dataset012_clint1pt/nnUNetTrainer_500epochs__nnUNetPlans__3d_fullres/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/Dataset013_MRFzclin/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres_last/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/Dataset014_MRFzclin/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/Dataset014_MRFzclin/nnUNetTrainer_250epochs__postprocessed2/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/Dataset015_MRFz/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres/')\n",
    "        'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/Dataset016_MRFz/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_Spencer/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/Dataset017_noCSF/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/Dataset022_T1wT1T2pt/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/Dataset016_MRFz/nnUNetTrainer_1000ep__nnUNetPlans__3d_fullres/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/Dataset002_MRF_small/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres/')\n",
    "        # 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/Dataset023_nosmooth/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres/')\n",
    "\n",
    "    binary_label_paths = list_labels(\n",
    "        'Z:/Imaging/Multimodal/MRF/Recon_MRF_3T/Patients/MRF_to_nnunet/nnUNet_raw/Dataset016_MRFz/labelsTr')\n",
    "    img = nib.load('Z:/Imaging/Multimodal/MRF/Peter/header.nii')\n",
    "\n",
    "\n",
    "    last_4 = {item[-16:] for item in nifti_file_paths}\n",
    "    print(last_4)\n",
    "    binary_label_paths = [item for item in binary_label_paths if item[-16:] in last_4]\n",
    "\n",
    "    nifti_file_paths = sorted(nifti_file_paths, key=lambda x: x[-16:])\n",
    "    binary_label_paths = sorted(binary_label_paths, key=lambda x: x[-16:])\n",
    "    # print(nifti_file_paths)\n",
    "    results = []\n",
    "    ol = 0\n",
    "    FPperP = 0\n",
    "    operls = []\n",
    "    withinls = []\n",
    "    dscs = []\n",
    "    for nifti_file_path, binary_label_path in zip(nifti_file_paths, binary_label_paths):\n",
    "        has_overlap, num_non_overlapping_clusters, newimg, oper, olwithin, dsc = process_nifti_file(nifti_file_path, binary_label_path)\n",
    "        results.append([nifti_file_path[-17:], int(has_overlap), num_non_overlapping_clusters, oper, olwithin, dsc])\n",
    "        if has_overlap:\n",
    "            ol = ol + 1\n",
    "            operls.append(oper)\n",
    "            withinls.append(olwithin)\n",
    "            dscs.append(dsc)\n",
    "        FPperP += num_non_overlapping_clusters\n",
    "\n",
    "    summary_df = pd.DataFrame(results, columns=[\"File\", \"Overlap\", \"# of FP Clusters\", \"overlap%\", \"withinlabel%\", \"dsc\"])\n",
    "    summary_df.to_excel('Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/OptimalPerformance.xlsx', index=False)\n",
    "    # print('niftis:\\n', len(nifti_file_paths))\n",
    "    # print('labels:\\n', len(binary_label_paths))\n",
    "    print(summary_df)\n",
    "    print(\"Total overlapped:\\n\", ol)\n",
    "    print(\"FP per patient:\\n\", FPperP / len(nifti_file_paths))\n",
    "    print(\"overlap per patient:\\n\", np.mean(np.array(operls)))\n",
    "    print(\"std overlap:\\n\", np.std(np.array(operls)))\n",
    "    print(\"ol within:\\n\", np.mean(np.array(withinls)))\n",
    "    print(\"std ol within:\\n\", np.std(np.array(withinls)))\n",
    "    print(\"dsc:\\n\", np.mean(np.array(dscs)))\n",
    "    print(\"std dsc:\\n\", np.std(np.array(dscs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789276b8-a485-4b24-9cf2-752ddb7dae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import pickle\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# 6 fold CV results check\n",
    "def process_nifti_file(nifti_file_path, binary_label_path):\n",
    "    img = nib.load(nifti_file_path)\n",
    "    data = img.get_fdata()\n",
    "    olwithin = 0\n",
    "    label_img = nib.load(binary_label_path)\n",
    "    label_data = label_img.get_fdata()\n",
    "    # Count non-overlapping clusters\n",
    "    overlap = (data.astype(int) & label_data.astype(int)).astype(bool)\n",
    "    overlap_per = np.sum((data.astype(int) & (label_data > 0).astype(int)))/(np.sum(label_data.astype(int)))\n",
    "    has_overlap = np.any(overlap)\n",
    "\n",
    "    structure = np.ones((3, 3, 3), dtype=int)\n",
    "    labeled_array, num_features = ndimage.label(data > 0, structure=structure)\n",
    "    \n",
    "    non_overlapping_clusters = 0\n",
    "    for cluster_id in range(1, num_features + 1):\n",
    "        cluster_mask = labeled_array == cluster_id\n",
    "        overlap = np.any(\n",
    "            cluster_mask & (label_data > 0))  # Assuming nonzero values in label_data indicate labeled regions\n",
    "        if not overlap:\n",
    "            non_overlapping_clusters += 1\n",
    "        else:\n",
    "            olwithin = np.sum(cluster_mask & (label_data > 0).astype(int))/(np.sum(cluster_mask))\n",
    "\n",
    "    return has_overlap, non_overlapping_clusters, data, overlap_per, olwithin\n",
    "\n",
    "\n",
    "def list_labels(directory):\n",
    "    file_paths = []  # List to store the file paths\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def list_outputs(directory):\n",
    "    file_paths = []  # List to store the file paths\n",
    "    entries = os.listdir(directory)\n",
    "    subfolder = directory\n",
    "    for root, dirs, files in os.walk(subfolder):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            if file.endswith('.nii.gz') and not file.endswith('_softmax.nii.gz'):\n",
    "                file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nifti_file_paths = list_outputs(\n",
    "        'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/6foldLOOCV/Dataset036_6fold6/prediction/')\n",
    "\n",
    "    binary_label_paths = list_labels(\n",
    "        'Z:/Imaging/Multimodal/MRF/Recon_MRF_3T/Patients/MRF_to_nnunet/nnUNet_raw/Dataset045_6fold20/labelsTs')\n",
    "    img = nib.load('Z:/Imaging/Multimodal/MRF/Peter/header.nii')\n",
    "\n",
    "    last_4 = {item[-16:] for item in nifti_file_paths}\n",
    "    binary_label_paths = [item for item in binary_label_paths if item[-16:] in last_4]\n",
    "\n",
    "    nifti_file_paths = sorted(nifti_file_paths, key=lambda x: x[-16:])\n",
    "    binary_label_paths = sorted(binary_label_paths, key=lambda x: x[-16:])\n",
    "    # print(nifti_file_paths)\n",
    "    # print(binary_label_paths)\n",
    "    results = []\n",
    "    ol = 0\n",
    "    FPperP = 0\n",
    "    operls = []\n",
    "    withinls = []\n",
    "    for nifti_file_path, binary_label_path in zip(nifti_file_paths, binary_label_paths):\n",
    "        has_overlap, num_non_overlapping_clusters, newimg, oper, olwithin = process_nifti_file(nifti_file_path, binary_label_path)\n",
    "        results.append([nifti_file_path[-17:], int(has_overlap), num_non_overlapping_clusters, oper, olwithin])\n",
    "        if has_overlap:\n",
    "            ol = ol + 1\n",
    "            operls.append(oper)\n",
    "            withinls.append(olwithin)\n",
    "        FPperP += num_non_overlapping_clusters\n",
    "\n",
    "    summary_df = pd.DataFrame(results, columns=[\"File\", \"Overlap\", \"# of FP Clusters\", \"overlap%\", \"withinlabel%\"])\n",
    "    excel_path = 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/6foldsLOOCVtest.xlsx'\n",
    "    book = load_workbook(excel_path)\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a' if book else 'w') as writer:\n",
    "        summary_df.to_excel(writer, sheet_name='test6', index=False)\n",
    "    print('niftis:\\n', len(nifti_file_paths))\n",
    "    print('labels:\\n', len(binary_label_paths))\n",
    "    print(summary_df)\n",
    "    print(\"Total overlapped:\\n\", ol)\n",
    "    print(\"FP per patient:\\n\", FPperP / len(nifti_file_paths))\n",
    "    print(\"overlap per patient:\\n\", np.mean(np.array(operls)))\n",
    "    print(\"std overlap:\\n\", np.std(np.array(operls)))\n",
    "    print(\"ol within:\\n\", np.mean(np.array(withinls)))\n",
    "    print(\"std ol within:\\n\", np.std(np.array(withinls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888431ca-928a-4729-8257-e63f4d6a0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import pickle\n",
    "\n",
    "def process_nifti_file(nifti_file_path, binary_label_path):\n",
    "    img = nib.load(nifti_file_path)\n",
    "    data = img.get_fdata()\n",
    "    olwithin = 0\n",
    "    label_img = nib.load(binary_label_path)\n",
    "    label_data = label_img.get_fdata()\n",
    "    # Count non-overlapping clusters\n",
    "    overlap = ((data.astype(float)>= 0.5) & label_data.astype(int)).astype(bool)\n",
    "    overlap_per = np.sum((data.astype(float)>= 0.5) & (label_data > 0).astype(int))/(np.sum(label_data.astype(int)))\n",
    "    has_overlap = np.any(overlap)\n",
    "    structure = np.ones((3, 3, 3), dtype=int)\n",
    "    labeled_array, num_features = ndimage.label(data >= 0.5, structure=structure)\n",
    "    \n",
    "    non_overlapping_clusters = 0\n",
    "    for cluster_id in range(1, num_features + 1):\n",
    "        cluster_mask = labeled_array == cluster_id\n",
    "        overlap = np.any(cluster_mask & (label_data > 0.5))  # Assuming nonzero values in label_data indicate labeled regions\n",
    "        if not overlap:\n",
    "            non_overlapping_clusters += 1\n",
    "        else:\n",
    "            olwithin = np.sum(cluster_mask & (label_data > 0).astype(int))/(np.sum(cluster_mask))\n",
    "\n",
    "    return has_overlap, non_overlapping_clusters, data, overlap_per, olwithin\n",
    "    # return has_overlap, non_overlapping_clusters, data\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    subjID=[(studyID)]\n",
    "    nifti_file_paths = []\n",
    "    binary_label_paths = []\n",
    "    for s in subjID:\n",
    "        nlp = \"Z:/Imaging/Multimodal/MRF/Recon_MRF_3T/Patients/\" + s + \"/MRF_VBM/MNI_lesionprob_ANN_fn.nii\"\n",
    "        blp = \"Z:/Imaging/Multimodal/MRF/Recon_MRF_3T/Patients/\" + s + \"/MRF_VBM/MNI_ROI_final.nii\"\n",
    "        nifti_file_paths.append(nlp)\n",
    "        binary_label_paths.append(blp)\n",
    "\n",
    "    img = nib.load('Z:/Imaging/Multimodal/MRF/Peter/header.nii')\n",
    "\n",
    "    results = []\n",
    "    ol = 0\n",
    "    FPperP = 0\n",
    "    operls = []\n",
    "    withinls = []\n",
    "    for nifti_file_path, binary_label_path in zip(nifti_file_paths, binary_label_paths):\n",
    "        has_overlap, num_non_overlapping_clusters, newimg, oper, olwithin = process_nifti_file(nifti_file_path, binary_label_path)\n",
    "        results.append([nifti_file_path[48:54], int(has_overlap), num_non_overlapping_clusters, oper, olwithin])\n",
    "        if has_overlap:\n",
    "            ol = ol + 1\n",
    "            operls.append(oper)\n",
    "            withinls.append(olwithin)\n",
    "        FPperP += num_non_overlapping_clusters\n",
    "\n",
    "    summary_df = pd.DataFrame(results, columns=[\"File\", \"Overlap\", \"# of FP Clusters\", \"overlap%\", \"withinlabel%\"])\n",
    "    # summary_df = pd.DataFrame(results, columns=[\"File\", \"Overlap\", \"# of FP Clusters\"])\n",
    "    summary_df.to_excel('Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV/MAP18.xlsx', index=False)\n",
    "    print('niftis:\\n', len(nifti_file_paths))\n",
    "    print('labels:\\n', len(binary_label_paths))\n",
    "    print(summary_df)\n",
    "    print(\"Total overlapped:\\n\", ol)\n",
    "    print(\"FP per patient:\\n\", FPperP / len(nifti_file_paths))\n",
    "    print(\"overlap per patient:\\n\", np.mean(np.array(operls)))\n",
    "    print(\"std overlap:\\n\", np.std(np.array(operls)))\n",
    "    print(\"ol within:\\n\", np.mean(np.array(withinls)))\n",
    "    print(\"std ol within:\\n\", np.std(np.array(withinls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from batchgenerators.utilities.file_and_folder_operations import join\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "nnUNet_results = 'Z:/Imaging/Multimodal/MRF/Peter/nnUNet_CV'\n",
    "nnUNet_raw = 'Z:/Imaging/Multimodal/MRF/Recon_MRF_3T/Patients/MRF_to_nnunet/nnUNet_raw'\n",
    "predictor = nnUNetPredictor(tile_step_size=0.5,\n",
    "        use_gaussian=True,\n",
    "        use_mirroring=True,\n",
    "        perform_everything_on_device=True,\n",
    "        device=torch.device('cuda', 0),\n",
    "        verbose=False,\n",
    "        verbose_preprocessing=False,\n",
    "        allow_tqdm=True)\n",
    "# initializes the network architecture, loads the checkpoint\n",
    "predictor.initialize_from_trained_model_folder(\n",
    "        join(nnUNet_results, 'Dataset009_MRF_clin/nnUNetTrainer_250epochs__nnUNetPlans__3d_fullres'),\n",
    "        use_folds=(21,),\n",
    "        checkpoint_name='checkpoint_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c788e2a-ab85-4c66-a9cc-a6f3fed32449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c96daf8-f7b3-4836-b54b-c5640e638c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.__getattribute__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8556ac1a-a8e4-491a-a058-920e4e5a9b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "model = resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d30fd06-02b3-4a77-8275-87e48dd887f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed4628-f6b0-4a24-8d48-b3a043bdd8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f359ea1-890c-41d3-8628-7a08241efe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.network.load_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8eb362-ca6d-4205-9f01-f6ca30082072",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.list_of_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c60077d-f464-4065-90f9-7c1c0168b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.network.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4905b2-20ce-422f-89a4-957d7d6231bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torchvision import models\n",
    "import torch.backends.cudnn as cudnn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364cd6a-4b3a-4f48-94fb-936775ea0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(predictor.network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6a240-84b2-466c-a6c0-3e4c4a9036fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in predictor.network.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#set model in eval mode\n",
    "predictor.network.eval()\n",
    "#transoform input PIL image to torch.Tensor and normalize\n",
    "input = transform(img)\n",
    "input.unsqueeze_(0)\n",
    "\n",
    "#we want to calculate gradient of higest score w.r.t. input\n",
    "#so set requires_grad to True for input \n",
    "input.requires_grad = True\n",
    "#forward pass to calculate predictions\n",
    "preds = predictor.network(input)\n",
    "score, indices = torch.max(preds, 1)\n",
    "#backward pass to get gradients of score predicted class w.r.t. input image\n",
    "predictor.network.backward()\n",
    "#get max along channel axis\n",
    "slc, _ = torch.max(torch.abs(input.grad[0]), dim=0)\n",
    "#normalize to [0..1]\n",
    "slc = (slc - slc.min())/(slc.max()-slc.min())\n",
    "\n",
    "#apply inverse transform on image\n",
    "with torch.no_grad():\n",
    "    input_img = inv_normalize(input[0])\n",
    "#plot image and its saleincy map\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(np.transpose(input_img.detach().numpy(), (1, 2, 0)))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(slc.numpy(), cmap=plt.cm.hot)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006fd203-cbcd-43f3-b6e2-8d05cd8809a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.network(torch.rand((8, 100, 100, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6aeba4-59c5-4db4-ab46-fc004d903dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnunetv2.imageio.simpleitk_reader_writer import SimpleITKIO\n",
    "img, props = SimpleITKIO().read_images([join(nnUNet_raw, 'Dataset003_Liver/imagesTr/liver_63_0000.nii.gz')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bda46e-2ad1-43a8-8787-524d7d008b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
